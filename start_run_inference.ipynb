{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import tkinter as tk\n",
    "import torch\n",
    "import model_training.config as config\n",
    "import model_training.utils as utils\n",
    "import inference.single_image_inference as inference\n",
    "import preprocessing.preprocess_data as preprocessing\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw, ImageTk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from model_training.model import YOLOv3\n",
    "from inference.plot_results import plot_bounding_boxes, plot_bounding_box_single_image, ImageDisplayApp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference Continuously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint: inference/model/inference_model_checkpoint.pth.tar\n",
      "Waiting for pcd files in label_cloud_project/datastore/pointclouds/raw_pcds\n",
      "000003.pcd\n",
      "Image saved at inference/temp/bev_images\\000003.png\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NMS\n",
      "Num boxes above confidence threshold: 10\n",
      "Highest Box confidence scores: [0.8072582483291626, 0.8008938431739807, 0.794102132320404, 0.7910056710243225, 0.7829733490943909]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 000003.pcd, bboxes: [[0, 0.0, 0.8072582483291626, 0.6199800968170166, 0.33954012393951416, 0.028397424146533012, 0.027723390609025955], [0, 0.0, 0.794102132320404, 0.4294567406177521, 0.37492313981056213, 0.028056034818291664, 0.02645588293671608], [0, 0.0, 0.7910056710243225, 0.4263358414173126, 0.2921159863471985, 0.028664518147706985, 0.028390057384967804], [0, 0.0, 0.7829733490943909, 0.6131014227867126, 0.43788930773735046, 0.026792213320732117, 0.026564495638012886], [0, 0.0, 0.7641777396202087, 0.4271423816680908, 0.432146817445755, 0.02818937413394451, 0.027177639305591583]]\n",
      "000004.pcd\n",
      "Image saved at inference/temp/bev_images\\000004.png\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NMS\n",
      "Num boxes above confidence threshold: 11\n",
      "Highest Box confidence scores: [0.8299436569213867, 0.824759304523468, 0.8069045543670654, 0.8013520836830139, 0.8003425598144531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 000004.pcd, bboxes: [[0, 0.0, 0.8299436569213867, 0.6207255721092224, 0.3393271267414093, 0.026913324370980263, 0.02635212615132332], [0, 0.0, 0.8069045543670654, 0.428894966840744, 0.37448444962501526, 0.027293629944324493, 0.02590077556669712], [0, 0.0, 0.8013520836830139, 0.6129134297370911, 0.4376993477344513, 0.026676852256059647, 0.02681625820696354], [0, 0.0, 0.8003425598144531, 0.42597758769989014, 0.29200875759124756, 0.028095433488488197, 0.02794303372502327], [0, 0.0, 0.7333654761314392, 0.4269472658634186, 0.43126749992370605, 0.028276219964027405, 0.027415188029408455]]\n",
      "000005.pcd\n",
      "Image saved at inference/temp/bev_images\\000005.png\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NMS\n",
      "Num boxes above confidence threshold: 13\n",
      "Highest Box confidence scores: [0.8456155061721802, 0.8389489650726318, 0.8136775493621826, 0.791598916053772, 0.7881207466125488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 000005.pcd, bboxes: [[0, 0.0, 0.8456155061721802, 0.6202619671821594, 0.3397262394428253, 0.027471937239170074, 0.026937486603856087], [0, 0.0, 0.8136775493621826, 0.42864885926246643, 0.37475278973579407, 0.027212966233491898, 0.025968434289097786], [0, 0.0, 0.791598916053772, 0.6124739050865173, 0.4379151463508606, 0.027056463062763214, 0.026983143761754036], [0, 0.0, 0.7881207466125488, 0.4258177578449249, 0.2921757698059082, 0.028848830610513687, 0.02836523950099945], [0, 0.0, 0.7778000831604004, 0.42670518159866333, 0.43271127343177795, 0.027141619473695755, 0.02731464058160782], [0, 0.0, 0.7280308604240417, 0.4677417278289795, 0.22481293976306915, 0.03291312977671623, 0.03196822479367256], [0, 0.0, 0.7113497257232666, 0.5802783966064453, 0.2078760266304016, 0.028882743790745735, 0.028339805081486702]]\n",
      "000006.pcd\n",
      "Image saved at inference/temp/bev_images\\000006.png\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m bev_image \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mtransform_to_bev(file_name)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Extract x, y coordinates from YOLO v3 output\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m bboxes_pred \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbev_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Print results to console\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, bboxes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbboxes_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\workspaces\\YOLO_BEV_APPROACH\\inference\\single_image_inference.py:57\u001b[0m, in \u001b[0;36minference_single_image\u001b[1;34m(model, image, confidence_threshold, nms_threshold)\u001b[0m\n\u001b[0;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Post-process the output\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m bboxes_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpost_process_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnms_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANCHORS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bboxes_pred\n",
      "File \u001b[1;32mf:\\workspaces\\YOLO_BEV_APPROACH\\inference\\single_image_inference.py:43\u001b[0m, in \u001b[0;36mpost_process_output\u001b[1;34m(dataloader, model, confidence_threshold, iou_threshold, anchors)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_process_output\u001b[39m(dataloader, model, confidence_threshold, iou_threshold, anchors):\n\u001b[1;32m---> 43\u001b[0m     bboxes_pred \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inference_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmidpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bboxes_pred\n",
      "File \u001b[1;32mf:\\workspaces\\YOLO_BEV_APPROACH\\model_training\\utils.py:399\u001b[0m, in \u001b[0;36mget_inference_bboxes\u001b[1;34m(loader, model, iou_threshold, anchors, confidence_threshold, box_format, device)\u001b[0m\n\u001b[0;32m    396\u001b[0m all_pred_boxes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    397\u001b[0m train_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(loader)):\n\u001b[0;32m    400\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py:326\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\quass\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_app = None\n",
    "\n",
    "def run_tkinter():\n",
    "    global global_app\n",
    "    root = tk.Tk()\n",
    "    global_app = ImageDisplayApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_id = f\"{config.INFERENCE_RUN_TITLE}_{current_datetime}\"\n",
    "\n",
    "# Create a folder for the run_id inside 'inference/inference_results/'\n",
    "results_folder = os.path.join(config.INFERENCE_RESULTS_FOLDER, run_id)\n",
    "processed_pcd_folder = config.INFERENCE_PROCESSED_PCD_FOLDER\n",
    "results_file_path = os.path.join(results_folder, f\"results_{run_id}.json\")\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "os.makedirs(processed_pcd_folder, exist_ok=True)\n",
    "\n",
    "if config.INFERENCE_SHOW_LIVE_RESULTS:\n",
    "    tkinter_thread = threading.Thread(target=run_tkinter)\n",
    "    tkinter_thread.start()\n",
    "\n",
    "model = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
    "utils.load_checkpoint(\n",
    "            config.INFERENCE_CHECKPOINT_FILE, model, None, None\n",
    "        )\n",
    "# Inference loop\n",
    "print(f\"Waiting for pcd files in {config.RAW_PCD_FOLDER}\")\n",
    "while True:\n",
    "    # Monitor the folder for new point cloud files\n",
    "    for file_name in os.listdir(config.INFERENCE_PCD_FOLDER):\n",
    "        print(file_name)\n",
    "        if file_name.endswith(\".pcd\"):\n",
    "            # Transform point cloud to BEV image\n",
    "            bev_image = preprocessing.transform_to_bev(file_name)\n",
    "\n",
    "            # Extract x, y coordinates from YOLO v3 output\n",
    "            bboxes_pred = inference.inference_single_image(model, bev_image)\n",
    "\n",
    "            # Print results to console\n",
    "            print(f\"File: {file_name}, bboxes: {bboxes_pred}\")\n",
    "\n",
    "            result_dict = {}\n",
    "            for idx in range(len(bboxes_pred)):\n",
    "                bbox_info = {\n",
    "                    \"confidence\": bboxes_pred[idx][2],\n",
    "                    \"x\": bboxes_pred[idx][3],\n",
    "                    \"y\": bboxes_pred[idx][4],\n",
    "                    \"w\": bboxes_pred[idx][5],\n",
    "                    \"h\": bboxes_pred[idx][6]\n",
    "                }\n",
    "                result_dict[idx] = bbox_info\n",
    "\n",
    "            # Create a dictionary to store all results\n",
    "            results = {}\n",
    "\n",
    "            # Check if the results file already exists\n",
    "            if os.path.exists(results_file_path):\n",
    "                # Read existing results from the file\n",
    "                with open(results_file_path, 'r') as json_file:\n",
    "                    results = json.load(json_file)\n",
    "\n",
    "            # Add new results to the dictionary\n",
    "            results[file_name] = result_dict\n",
    "\n",
    "            if config.INFERENCE_SHOW_LIVE_RESULTS:\n",
    "                plot_bounding_box_single_image(result_dict, config.INFERENCE_TEMP_BEV_FOLDER, file_name, global_app)\n",
    "\n",
    "            # Write all results back to the file\n",
    "            with open(results_file_path, \"w\") as json_file:\n",
    "                json.dump(results, json_file, indent=2)\n",
    "\n",
    "            # Optional: Move processed file to another folder to avoid re-processing\n",
    "            os.rename(os.path.join(config.INFERENCE_PCD_FOLDER, file_name),\n",
    "                      os.path.join(processed_pcd_folder, file_name))\n",
    "\n",
    "    # Sleep for a while before checking for new files again\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all results on top of BEV images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_boxes(results_file_path, config.INFERENCE_TEMP_BEV_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
